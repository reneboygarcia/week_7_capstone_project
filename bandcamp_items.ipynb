{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 51884 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "from distributed import Client\n",
    "client = Client()\n",
    "# import pandas as pd\n",
    "import modin.pandas as pd\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "from google.cloud import bigquery\n",
    "from prefect import task, flow\n",
    "from prefect_gcp.cloud_storage import GcsBucket\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq 1-Define a function to convert the downloaded file to data frame\n",
    "def read_df(file: str) -> pd.DataFrame:\n",
    "    with open(file) as data_file:\n",
    "        data = json.load(data_file)\n",
    "        df = pd.read_json(data)\n",
    "        df = pd.json_normalize(df, sep=\"_\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq 2-Define a function to tweak the data frame\n",
    "def tweak_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(f\"Number of rows: {df.shape[0]}\")\n",
    "    df_ = df\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq 3-Define a function to set a path for GCS storage and for local file\n",
    "def write_local(df: pd.DataFrame, filename: str) -> Path:\n",
    "    directory = Path(\"bandcamp\")\n",
    "    _file_name = filename.split(\".\")[0]\n",
    "    path_name = directory / f\"{_file_name}.parquet\"\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "        pd.to_parquet(path_name, compression=\"gzip\", index=False)\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "    return path_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq 4-Define a function to upload local file to GCS Bucket\n",
    "def write_to_gcs(path: Path) -> None:\n",
    "    gcs_block = GcsBucket.load(\"prefect-gcs-block-bandcamp\")\n",
    "    gcs_block.upload_from_path(from_path=path, to_path=path)\n",
    "    print(\"Hooray, we uploaded a huge file in GCS\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq 5-Delete local file and its directory\n",
    "def duduplicate(path: Path) -> None:\n",
    "    try:\n",
    "        path.unlink()\n",
    "        full_path = path.resolve()\n",
    "        full_path.parent.rmdir()\n",
    "        print(\"Successfully deleted directory and its files\")\n",
    "    except OSError as error:\n",
    "        print(f\"Unable to find directory: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ETL from web to gcs:\n",
    "def etl_web_to_gcs(file: str):\n",
    "    # Seq 1 -Read file\n",
    "    df = read_df(file)\n",
    "    # Seq 2 -Tweak df\n",
    "    df_ = tweak_df(df)\n",
    "    # Seq 3 -Set a path this will be use to convert file to parquet\n",
    "    path_file = write_local(df, file)\n",
    "    # Seq 4-Upload local file to GCS Bucket\n",
    "    write_to_gcs(path_file)\n",
    "    # Seq 5- Remove duplicate\n",
    "    duduplicate(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define download progress hook\n",
    "def download_progress_hook(block_num, block_size, total_size):\n",
    "    global progress_bar\n",
    "    if not progress_bar:\n",
    "        progress_bar = tqdm(total=total_size, unit='B', unit_scale=True)\n",
    "    downloaded = block_num * block_size\n",
    "    progress_bar.update(downloaded - progress_bar.n)\n",
    "    if downloaded >= total_size:\n",
    "        progress_bar = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seq 0 -Download file folder from web\n",
    "def fetch_data(url:str):\n",
    "    folder_name = url.split(\"/\")[-1].split(\"?\")[0]\n",
    "    file_folder = urlretrieve(url, folder_name, reporthook=download_progress_hook)\n",
    "    if folder_name.endswith(\".zip\"):\n",
    "        unzipped_folder = ZipFile(folder_name).extractall()\n",
    "        print(f\"Download Complete..extracted zip file\")\n",
    "        return unzipped_folder\n",
    "    print(f\"Download Complete..\")\n",
    "    return file_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80.6MB [00:34, 2.31MB/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Complete..extracted zip file\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "dataset_url_2 = \"https://www.dropbox.com/s/wd38q80el16i19q/1000000-bandcamp-sales.zip?dl=1\"\n",
    "progress_bar = None\n",
    "data_folder = fetch_data(dataset_url_2)\n",
    "for f in os.listdir(data_folder):\n",
    "    if f.endswith(\".csv\"):\n",
    "        print(\"testing\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a parent ETL to download the files\n",
    "def el_parent_web_gcs():\n",
    "    # Parameters\n",
    "    dataset_url = \"https://www.dropbox.com/s/a1kl5e35j4o53mz/bandcamp-items-json.zip?dl=1\"\n",
    "\n",
    "    # Execution\n",
    "    # Seq 0 -Download file folder from web\n",
    "    progress_bar = None\n",
    "    file_folder = fetch_data(dataset_url)\n",
    "    # Loop through the files then run etl_web_to_gcs\n",
    "    print(\"Running etl_web_to_gcs...this will take sometime..grab some coffee or tea\")\n",
    "    for f in os.listdir(file_folder):\n",
    "        if f.endswith(\".json\"):\n",
    "            print(\"Running: {f}\")\n",
    "            etl_web_to_gcs(f)\n",
    "            print(\"Done uploading {f} to GCS\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
