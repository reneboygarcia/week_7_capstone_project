{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import typing\n",
    "from prefect import task, flow\n",
    "from prefect_gcp import GcpCredentials\n",
    "from google.cloud import bigquery\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment 2\n",
    "@task(log_prints=True, name=\"get-gcp-creds\")\n",
    "# Define a function to get GCP Credentials\n",
    "def get_bigquery_client():\n",
    "    gcp_creds_block = GcpCredentials.load(\n",
    "        \"prefect-gcs-2023-creds\"\n",
    "    )  # Change this credentials to yours\n",
    "    gcp_creds = gcp_creds_block.get_credentials_from_service_account()\n",
    "    client = bigquery.Client(credentials=gcp_creds)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/prefect/flows.py:214: UserWarning: A flow named 'etl-gcs-to-bq' and defined at '/var/folders/h2/6110hgtx6b7400ybw7yjhn400000gn/T/ipykernel_24489/1994146814.py:2' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n",
      "\n",
      " `@flow(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Upload data from GCS to BigQuery\n",
    "@flow(log_prints=True, name=\"etl-gcs-to-bq\")\n",
    "def etl_gcs_to_bq(file_num: int):\n",
    "    client = get_bigquery_client()\n",
    "    table_id = f\"dtc-de-2023.stg_bandcamp.albums-full-info-{file_num}\"\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.PARQUET,\n",
    "        schema=[\n",
    "            bigquery.SchemaField(\"_id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"numTracks\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"keywords\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"datePublished\", \"DATETIME\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"name\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"dateModified\", \"DATETIME\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"comment\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"description\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"inAlbum\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"offers\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"duration_secs\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"url\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"duration\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"isrcCode\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"byArtist_image\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"byArtist_genre\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"byArtist_@id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"byArtist_@type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"byArtist_sameAs\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"byArtist_name\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"byArtist_description\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"track_itemListElement\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"track_@type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"track_numberOfItems\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"track\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"inAlbum_name\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"inAlbum_@id\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"inAlbum_@type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"offers_availability\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\n",
    "                \"offers_priceSpecification_minPrice\", \"FLOAT\", mode=\"NULLABLE\"\n",
    "            ),\n",
    "            bigquery.SchemaField(\"offers_price\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"offers_@type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"offers_priceCurrency\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"offers_url\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"recordingOf_@type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"recordingOf_lyrics_text\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"recordingOf_lyrics_@type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "            bigquery.SchemaField(\"byArtist\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "        ],\n",
    "    )\n",
    "    uri = f\"gs://prefect-gcs-bucket-bandcamp/albums-full-info-{file_num}\"\n",
    "\n",
    "    load_job = client.load_table_from_uri(\n",
    "        uri, table_id, job_config=job_config\n",
    "    )  # Make an API request.\n",
    "\n",
    "    load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "    destination_table = client.get_table(table_id)\n",
    "    print(f\"Loaded {destination_table.num_rows} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow(log_prints=True, name=\"deduplicate data\")\n",
    "# Define a function to remove duplicate\n",
    "def deduplicate_data(num: int):\n",
    "    client = get_bigquery_client()\n",
    "\n",
    "    query_dedup = f\"CREATE OR REPLACE TABLE \\\n",
    "                        `dtc-de-2023.stg_bandcamp.albums-full-info-{num}`  AS ( \\\n",
    "                            SELECT DISTINCT * \\\n",
    "                            FROM `dtc-de-2023.stg_bandcamp.albums-full-info-{num}` \\\n",
    "                            )\"\n",
    "\n",
    "    # limit query to 10GB\n",
    "    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "    # priority=bigquery.QueryPriority.BATCH\n",
    "    # query\n",
    "    query_job = client.query(query_dedup, job_config=safe_config)\n",
    "\n",
    "    # Check progress\n",
    "    query_job = typing.cast(\n",
    "        \"bigquery.QueryJob\",\n",
    "        client.get_job(\n",
    "            query_job.job_id, location=query_job.location\n",
    "        ),  # Make an API request.\n",
    "    )\n",
    "    print(\"Complete removing duplicates\")\n",
    "    print(f\"Job {query_job.job_id} is currently in state {query_job.state}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE_LIST = [f\"albums-full-info-{file_num}\" for file_num in range(1,12)] \n",
    "# TABLE_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union all tables\n",
    "def union_all():\n",
    "    # Parameters\n",
    "    client = get_bigquery_client()\n",
    "    project_id = \"dtc-de-2023\"\n",
    "    dataset_id = \"stg_bandcamp\"\n",
    "    table_list = [f\"albums-full-info-{file_num}\" for file_num in range(1,12)]\n",
    "    # Query\n",
    "    query_template = \"SELECT * FROM `{project_id}.{dataset_id}.{table_name}`\"\n",
    "    union_table_name = \"bandcamp_items_all\"\n",
    "    destination_table_id = f\"{project_id}.{dataset_id}.{union_table_name}\"\n",
    "    \n",
    "    union_query = \"\\nUNION ALL\\n\".join([query_template.format(project_id=project_id, dataset_id=dataset_id, table_name=table) for table in table_list])\n",
    "    \n",
    "    job_config = bigquery.QueryJobConfig(destination=destination_table_id, write_disposition=\"WRITE_TRUNCATE\")\n",
    "    job = client.query(query=union_query, job_config=job_config)\n",
    "    job.result\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent flow ETL\n",
    "@flow(log_prints=True, name=\"etl-parent-to-bq\")\n",
    "def etl_parent_bq_flow(file_num_list: list[int] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]):\n",
    "    for file_num in file_num_list:\n",
    "        etl_gcs_to_bq(file_num)\n",
    "    # Union all tables\n",
    "    union_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run main\n",
    "if __name__ == \"__main__\":\n",
    "    file_num_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "\n",
    "    etl_parent_bq_flow(file_num_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
